\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{biblatex}
\usepackage{todonotes}

% TODO: Tren og evaluer standard 300, kompleks 300, attention bot
% skriv rapport
% Kok fra den andre rapportgreia

\addbibresource{references.bib}

\title{Language Agnostic Generative Chatbot using Personal Chatlog Data}
\author{Torjus Iveland \& Vegar Andreas Bergum}
\date{April 2019}

\begin{document}

\maketitle

\begin{abstract}

In this report, we explore the state of Norwegian chatbot systems with
the aim of verifying that conventional English chatbot creation techniques
also can be used to create chatbots which converse in Norwegian. There are
multiple challenges with Norwegian chatbots, due to the syntactic structure
of the language as well as the lack of available training data.

\paragraph{}
We present an implementation of a generic-domain chatbot system using a simple
sequence-to-sequence model, a kind of model which primarily is applied to
neural machine translation but which also has proven effective for chatbot
systems. We believe our results illustrate that neural machine translation
techniques indeed can be applied to create chatbots in both Norwegian as
well as English, as long as enough training data of a sufficiently high
quality is available. However, we stress that in many cases such training
data in Norwegian can be hard to obtain.

\end{abstract}

\section{Introduction}

A chatbot is a computer system which can interact with an user through natural
languge. Because humans tend to prefer more human-like interfaces, chatbots can
be very useful in applications
such as customer support, education, and personal productivity systems like
Google Assistant.  This project concerns such chatbots which converse
specifically using the Norwwegian language.

\paragraph{}
Most research on chatbot systems concerns chatbots which converse in English.
However, Norwegian has a syntactic structure which differs from that of
English. Therefore, it is not guaranteed that this research automatically
applies to Norwegian chatbots as well. Additionally, further problems arise
from the fact that training data in Norwegian is not as abundant as for
English.

\paragraph{}
In this project, we explore Norwegian chatbots, with the goal of verifying that
conventional chatbot-creation techniques also can function adequately in
Norwegian. We especially want to verify that deep learning techniques such as
sequence-to-sequence models \cite{Cho2014} can be used to create
general-purpose Norwegian chatbots. Such models are usually used for machine
translation, but they have also proven efective in the field of chatbots. The
main objective of this project is therefore to implement a simple Norwegian
chatbot using a sequence-to-sequence model, which for example could be used as
a smalltalk module in another mode domain-specific chatbot.

\paragraph{}
We differ between retrieval-based and generative chatbots. A retrieval-based
system usually map an user input to a predefined intent, and then retrieve an
answer from a set of answers belonging to the detected intent. A generative
system does not rely on such predefined sets of answers.  Instead, they are
able to automatically generate an answer to the provided query. In this
project, we restrict ourselves to the latter kind of model. We also restrict
ourselves to an user-initiative only model, which means that the chatbot simply
responds with an answer to each user query.

\if
- Something about how we want to structure the rest of the report.  
- Fix that goal, motivation, question and hypothesis are not clear.  
- Attention \cite{Bahdanau2015}, BERT and similar when we hopefully begin using it.
\fi

\section{Method}

% I dette kapitlet skal du skrive om hvordan du har gått frem metodisk, og vise
% hvordan valg av design og metode egner seg til å svare på problemstillingen
% din.  Kapitlet må kunne gi svar på disse spørsmålene: Hvordan samlet du inn
% datamaterialet?  Hvordan behandlet du dataene du samlet inn?  Hvorfor valgte
% du disse metodene?  Hva er styrkene og svakehetene ved disse metodene?  Du
% skal også si noe om hvorfor du har gjort din undersøkelse på den måten du
% gjorde – og da peke på styrker og svakheter. I tillegg skal du drøfte etiske
% aspekter ved prosjektet. På den måten viser du at du har kommet frem til
% resultatene på en pålitelig og troverdig måte, men også at du er reflektert
% og kritisk overfor arbeidet du har gjort.  Husk også at du her, slik som i
% teorikapitlet, bare skal skrive om det metodiske som er relevant for din
% studie.

\if
 - Prøvd ut pre-existing modeller med forskjellige datasett
    - engelsk datasett som vi vet er av god kvalitet
    - forskjellige attention-modeller
 - Sammenlignet egne modeller og eget datasett mot dette
 - Ressursbegrensning (datakraft og tid) har begrenset omfanget på evaluering
 av forskjellige modeller
\fi

\section{Data}

Norwegian chatbot training data is not readily available, but relevant corpora
still exist.  For example, multiple spoken language corpora are available
through the CLARINO project \cite{clarino-about}. Examples of CLARINO
corpora which might prove useful for a chatbot project are the Big Brother
corpus \cite{clarino-bb} and NoTa-Oslo \cite{clarino-nota}, which both provide
spoken language annotations for he Norwegian language. However, both these
corpora have quite restrictive licenses and are only accessible online for
privacy reasons. Thus, the CLARINO corpora are not well suited for our chatbot
usage.

\paragraph{}
Another possible data source is to use exports of personal chatbot data from
various online platforms, For example, Facebook allows users to export their
private Messenger chat data. If all parties involved in a conversation consent,
such data can be used to train a chatbot. An average Facebook user will quite
easily be able to generate several tens of thousands of utterances over the
course of a few years. More avid users of the platform can have chat logs
containing several hundred thousands or even millions of messages. This project
combines the utterances of two Facebook users, ending in a corpus with more
than 110,000 utterance pairs.

\todo{vil vi ha med noe om challenges mtp at svar kan variere veldig fra person
til person?}

\paragraph{}
In addition to using personal Facebook Messenger data, the Cornell Movie
Dialogs Corpus \cite{cornell-corpus} has been used for model evaluation. The
Cornell corpus consists of several hundreds of thousands utterances from movie
scripts that are freely available. This corpus is frequently highlighted in
chatbot models as a high quality data set.

\if
- Difficulties with chatbot data 
- We use chatbot data, want to check if it is possible to use real chatlot data
to create a language-agnostic bot 
- English dataset usage
\fi

\section{Implementation}

Chatbots which utilise deep learning are usually based on sequence to sequence
models. A sequence to sequence model is a type of architecture where there is
an encoder RNN and a decoder RNN. For usages such as machine translation and
chatbots, the idea is that we feed the encoder RNN input words one at a time,
which eventually results in an output vector describing the input sentence.
This output vector is sometimes referred to as a thought vector, as it stores
the systems understanding of the input. For machine translation, we would feed
the encoder RNN the sentence to be translated, and for chatbots, the encoder
RNN would accept the input sentence which should be responded to. The decoder
RNN is trained to take thought vectors from the encoder and output tokens
one by one until an end of sequence token is outputted. Since the decoder
network is dependent on the output of the encoder network, both networks are
trained together. This simple model has proven very effective for neural
machine translation and other tasks as well. An early description of this
architecture is available in \cite{Cho2014}.

\subsection{Preprocessing}

Before the data is forwarded to the model, it needs to be preprocessed. The
preprocessing phase in this project consists of a number of steps. We use
data from Facebook Messenger to train our chatbot. To split the data into
input and target data sets, we simply treat each utterance as the input to
the next utterance - that is, each utterance is the response to the previous.

\paragraph{}
First, text is normalized by removing all punctuation from the text. Newlines
are replaced with spaces, and all text is converted to lower-case. Ideally,
the bot should output grammatically correct text, but this requires a
significantly more complex model. We use the Norwegian NLTK tokenizer to split
the text into words. Lastly, each utterance is wrappde in a special stard and
end token, which indicates to the model when it should stop generating text
during the inference phase.
\todo{Might not want to use the word inference phase, not defined.}

\paragraph{}
The preprocessing system also performs filtering on which utterances should
and should not be used. For example, the system can be configured to only
use responses from a specific person, to give the chatbot a more distinct
persionality. Additionally, the system can removes self-replies, so that
only discourse between two different persons is considered.

\paragraph{}
The maximum length of an input or target utterance is capped at 20 tokens.
This is required to reduce the size of the input matrices for the model, due
to limited available computational power. However, an analysis of the dataset
shows that only about 4\% of the utterances are above this limit. Similarly,
we limit the number of words which may appear in the input and target data.
This vocabulary size only includes the most common 3000 words. In accordance
with Zipf's law, 3000 words accounts for slightly under 80\% of the total
vocabulary. While this might reduce the quality of the output due to certain
parts of the output sentences being omitted, it is crucial that the size of
the input vectors is minimized.

\paragraph{}
The preprocessing system also provides a way of encoding utterances as
vectors, a process known as word embedding. This is done by simply
encoding each token as an unique number, with additional logic for handling
unknown tokens. Note that this is a very simple embedding tecnnique, and
therefore future work might include exploring alternative embedding techniques
such as \emph{word2vec} or \emph{BERT}.

\subsection{Model}

This project utilises a fairly standard sequence-to-sequence model implemented
using Keras.

TODO: Describe number of layers, draw a diagram. Explain that we use LSTM nodes.
Object oriented system. Model is stored, can be loaded. token mappers are also
stored. how we fit the model. epochs, batches. model printout.

\subsection{Inference}

\subsection{}

want to take input (x1, x2, ...) and map to ouput (y1, y2, ...). could work for nmt. first, lets have encoder rnn (lstm or gru),
feed it french words 1 at a time. then we get output vector representing input sentence. then we build a decoder network,
takes encoding output from encoder network and then is trained to output the translation word by word until it spits out an end of sequence token
 ite. this works pretty well for nmt and other applications. 



one hot

model type

preprocessing specifics

- vocabulary

mode specifics

inference shit


appendix: conversation data


\if
- seq2seq 
- preprocessing of norwegian data - describe stack 
- teacher forcing
\fi

% Architecture \ Experimental Setup + Teacher forcing Future work: Bert/custom
% embeddings, embedding layer, bidirectional model, beam search

\section{Results}

% Å analysere gjør du ved å redegjøre, forklare og vurdere funnene dine.
% Analysedelen av oppgaven blir ofte kalt resultater, slik som i
% IMRoD-modellen.  I kvantitative studier vil du kanskje i tillegg til å
% presentere funnene skriflig, bruke figurer og tabeller for å gi leseren en
% oversikt og innsikt i hva du har gjort.  I empirisk baserte studier vil
% analysene handle om å beskrive og tolke. Mange vil ofte drøfte enkeltfunnene
% i dette kapitlet og ta for seg mer overordnede funn i drøftingskapitlet.

\section{Discussion / Evaluation}

% Du skal her drøfte resultatene dine og sette dem inn i en sammenheng. Å
% drøfte vil si å: sette ulike synspunkter, momenter, argumenter, faktorer og
% årsaker opp mot hverandre vurdere og sette dem opp mot hadily available, this
% is one of the primary challenges.  + Facebook Messenger data dump.  +
% Clarino: Tried, but restrictive licenses.  + Movie scripts. Copyright
% unclear.

\section{Related Work}

Multiple Norwegian chatbots already exist. However, these are usually systems
which first map the user query to a predefined intent, and then retrieve an
answer from a list of answers belonging to the intent. Such systems require a
fair amount of manual training, and lack the ability to independently formulate
an answer independently, based only on the question.  In this report, we
describe a generative chatbot which is based on an unsupervised model.

\section{Results}

% Å analysere gjør du ved å redegjøre, forklare og vurdere funnene dine.
% Analysedelen av oppgaven blir ofte kalt resultater, slik som i
% IMRoD-modellen.  I kvantitative studier vil du kanskje i tillegg til å
% presentere funnene skriflig, bruke figurer og tabeller for å gi leseren en
% oversikt og innsikt i hva du har gjort.  I empirisk baserte studier vil
% analysene handle om å beskrive og tolke. Mange vil ofte drøfte enkeltfunnene
% i dette kapitlet og ta for seg mer overordnede funn i drøftingskapitlet.

\section{Discussion / Evaluation}

% Du skal her drøfte resultatene dine og sette dem inn i en sammenheng. Å
% drøfte vil si å: sette ulike synspunkter, momenter, argumenter, faktorer og
% årsaker opp mot hverandre vurdere og sette dem opp mot hverandre. Finnes det
% flere ulike tolkninger av resultatene?

% heavily biased dataset bad training data, not so much training data simple
% model

% heavily biased dataset
% bad training data, not so much training data
% simple model

\section{Conclusions}

% Om avslutningen din skal være en konklusjon eller en oppsummering, avhenger
% av problemstillingen din. En konklusjon skal svare på problemstillingen, mens
% en oppsummering gjentar det viktigste fra oppgaven. Det er ikke uvanlig å
% velge en kombinasjon av de to, hvor du både oppsummerer oppgaven kort, men
% også svarer på problemstillingen.  Det er lurt å la avslutningen speile
% innledningen, ved å si hva du har gjort. Avslutningen bør også sette oppgaven
% din i et større perspektiv, og peke på hvilke muligheter du ser ut fra ditt
% prosjekt. Hvilke bidrag har din undersøke gitt til faget? Er det noe som
% burde blitt studert ytterligere? Slik tar du utgangspunkt i ditt eget
% prosjekt og peker på mulighet for oppfølging.

\printbibliography

\end{document}
